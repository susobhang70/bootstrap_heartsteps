{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import rpy2.robjects as robjects\n",
    "from collections import OrderedDict\n",
    "import scipy.stats as stats\n",
    "import scipy.linalg as linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PKL_DATA_PATH = \"/Users/raphaelkim/Dropbox (Harvard University)/HeartStepsV2V3/Raphael/all91.pkl\"\n",
    "PRIOR_DATA_PATH = \"/Users/raphaelkim/Dropbox (Harvard University)/HeartStepsV2V3/Raphael/bandit-prior.RData\"\n",
    "NDAYS = 90\n",
    "NUSERS = 91\n",
    "NTIMES = 5\n",
    "\n",
    "N_POST_SAMPLES = 5000\n",
    "\n",
    "F_KEYS = [\"intercept\", \"dosage\", \"engagement\", \"other_location\", \"variation\"]\n",
    "G_KEYS = [\"intercept\", \"dosage\", \"engagement\", \"other_location\", \"variation\", \"temperature\", \"logpresteps\", \"sqrt_totalsteps\"]\n",
    "\n",
    "E0 = 0.2\n",
    "E1 = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_data():\n",
    "    with open(PKL_DATA_PATH, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_user_state(data):\n",
    "    '''Determine the state of each user at each time point'''\n",
    "    availability = data[2]\n",
    "\n",
    "    features = OrderedDict()\n",
    "    features[\"intercept\"] = 1\n",
    "    features[\"dosage\"] = data[6]\n",
    "    features[\"engagement\"] = data[7]\n",
    "    features[\"other_location\"] = data[8]\n",
    "    # features[\"work_location\"] = data[9]\n",
    "    features[\"variation\"] = data[10]\n",
    "    features[\"temperature\"] = data[11]\n",
    "    features[\"logpresteps\"] = data[12]\n",
    "    features[\"sqrt_totalsteps\"] = data[13]\n",
    "    # features[\"prior_anti\"] = data[14]\n",
    "\n",
    "    fs = np.array([v for k,v in features.items() if k in F_KEYS])\n",
    "    gs = np.array([v for k,v in features.items() if k in G_KEYS])\n",
    "\n",
    "    return availability, fs, gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_priors():\n",
    "    '''Load priors from RData file'''\n",
    "    robjects.r['load'](PRIOR_DATA_PATH)\n",
    "    priors = robjects.r['bandit.prior']\n",
    "    alpha_pmean = np.array(priors.rx2(\"mu1\"))\n",
    "    alpha_psd = np.array(priors.rx2(\"Sigma1\"))\n",
    "    beta_pmean = np.array(priors.rx2(\"mu2\"))\n",
    "    beta_psd = np.array(priors.rx2(\"Sigma2\"))\n",
    "    sigma = float(priors.rx2(\"sigma\")[0])\n",
    "\n",
    "    prior_sigma = linalg.block_diag(alpha_psd, beta_psd, beta_psd)\n",
    "    prior_mu = np.concatenate([alpha_pmean, beta_pmean, beta_pmean])\n",
    "\n",
    "    return prior_sigma, prior_mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_priors_alpha_beta(post_mu, post_sigma):\n",
    "    '''Get alpha and beta priors from mu and sigma'''\n",
    "    alpha_pmean = post_mu[:len(G_KEYS)].flatten()\n",
    "    alpha_psd = post_sigma[:len(G_KEYS), :len(G_KEYS)]\n",
    "    beta_pmean = post_mu[-len(F_KEYS):].flatten()\n",
    "    beta_psd = post_sigma[-len(F_KEYS):, -len(F_KEYS):]\n",
    "\n",
    "    return alpha_pmean, alpha_psd, beta_pmean, beta_psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_lr_params(alpha_pmean, alpha_psd, beta_pmean, beta_psd, sigma):\n",
    "    '''Sample alpha, beta and noise from priors for BLR'''\n",
    "\n",
    "    alpha0 = np.random.multivariate_normal(alpha_pmean, alpha_psd)\n",
    "    alpha1 = np.random.multivariate_normal(beta_pmean, beta_psd)\n",
    "    beta = np.random.multivariate_normal(beta_pmean, beta_psd)\n",
    "    et = np.random.normal(0, np.sqrt(sigma**2))\n",
    "\n",
    "    return alpha0, alpha1, beta, et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(x, eta = .2):#.2 is used in Peng's code\n",
    "    '''Clipping function'''\n",
    "    return min(1 - E0, max(x, E1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_draws_beta(post_mu, post_sigma, n=N_POST_SAMPLES):\n",
    "    '''Draw n samples from beta's multivariate normal distribution'''\n",
    "    _, _, beta_pmean, beta_psd = get_priors_alpha_beta(post_mu, post_sigma)\n",
    "    return np.random.multivariate_normal(beta_pmean, beta_psd, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_post_prob(fs, posterior_draws, eta = 0):\n",
    "    '''Calculate the posterior probability of Pr(fs * b > eta)'''\n",
    "    positive_samples = len(np.where(posterior_draws @ fs > eta)[0])\n",
    "    post_prob = positive_samples / N_POST_SAMPLES\n",
    "    phi_prob = clip(post_prob)\n",
    "    return phi_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reward(post_mu, post_sigma, fs, gs, sigma, action, prob):\n",
    "\n",
    "    # Get priors for alpha and beta\n",
    "    alpha_pmean, alpha_psd, beta_pmean, beta_psd = get_priors_alpha_beta(post_mu, post_sigma)\n",
    "\n",
    "    # Sample alpha, beta and noise\n",
    "    alpha0, alpha1, beta, et = sample_lr_params(alpha_pmean, alpha_psd, beta_pmean, beta_psd, sigma)\n",
    "\n",
    "    # Calculate reward\n",
    "    reward = gs @ alpha0 + (prob * (fs @ alpha1)) + (action - prob) * (fs @ beta) + et\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_phi(prob_matrix, action_matrix, fs_matrix, gs_matrix):\n",
    "    Phi = np.expand_dims(np.hstack((gs_matrix, fs_matrix * prob_matrix.reshape(-1, 1), \\\n",
    "                (fs_matrix * (action_matrix - prob_matrix).reshape(-1, 1)))), axis=2)\n",
    "    return Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_post_sigma(prior_sigma, sigma, availability_matrix, Phi):\n",
    "    '''Calculate the posterior sigma'''\n",
    "\n",
    "    # Phi squared\n",
    "    Phi_square = np.multiply(Phi, Phi.transpose(0, 2, 1))\n",
    "\n",
    "    # Sum of availability times Phi squared\n",
    "    avail_phi_squared_sum = np.sum(np.multiply(availability_matrix.reshape(-1, 1, 1), Phi_square), axis=0) / (sigma**2)\n",
    "\n",
    "    # Posterior sigma\n",
    "    post_sigma = np.linalg.inv(np.linalg.inv(prior_sigma) + avail_phi_squared_sum)\n",
    "\n",
    "    return post_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_post_mu(prior_sigma, prior_mu, sigma, availability_matrix, reward_matrix, Phi, post_sigma):\n",
    "    '''Calculate the posterior mu'''\n",
    "\n",
    "    # Product of prior sigma inverse and prior mu\n",
    "    sig_mu = (np.linalg.inv(prior_sigma) @ prior_mu.T).reshape(-1, 1)\n",
    "    \n",
    "    # Product of Phi and reward\n",
    "    Phi_reward = np.multiply(Phi, reward_matrix.reshape(-1, 1, 1))\n",
    "\n",
    "    # Sum of availability times Phi and reward\n",
    "    avail_phi_reward_sum = np.sum(np.multiply(availability_matrix.reshape(-1, 1, 1), Phi_reward), axis=0)\n",
    "\n",
    "    # Posterior mu\n",
    "    post_mu = (post_sigma @ (sig_mu + (avail_phi_reward_sum/(sigma ** 2))) )\n",
    "\n",
    "    return post_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_posterior(prior_sigma, prior_mu, sigma, availability_matrix, prob_matrix, reward_matrix, action_matrix, fs_matrix, gs_matrix):\n",
    "    '''Calculate the posterior distribution'''\n",
    "    \n",
    "    # Calculate phi(s, a)\n",
    "    Phi = calculate_phi(prob_matrix, action_matrix, fs_matrix, gs_matrix)\n",
    "\n",
    "    # Calculate posterior sigma\n",
    "    post_sigma = calculate_post_sigma(prior_sigma, sigma, availability_matrix, Phi)\n",
    "\n",
    "    # Calculate posterior mu\n",
    "    post_mu = calculate_post_mu(prior_sigma, prior_mu, sigma, availability_matrix, reward_matrix, Phi, post_sigma)\n",
    "    \n",
    "    return post_mu[:,0], post_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(p):\n",
    "    '''Select action from bernoulli distribution with probability p'''\n",
    "    return stats.bernoulli.rvs(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = load_data()\n",
    "\n",
    "# Load priors\n",
    "prior_sigma, prior_mu, sigma = load_priors()\n",
    "\n",
    "# Posterior initialized using priors\n",
    "post_sigma, post_mu = np.copy(prior_sigma), np.copy(prior_mu)\n",
    "\n",
    "# DS to store availability, probabilities, features, actions and rewards\n",
    "availability_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "prob_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "reward_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "action_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "fs_matrix = np.zeros((NUSERS, NDAYS * NTIMES, len(F_KEYS)))\n",
    "gs_matrix = np.zeros((NUSERS, NDAYS * NTIMES, len(G_KEYS)))\n",
    "\n",
    "\n",
    "for user in range(NUSERS):\n",
    "# for user in range(80, 90):\n",
    "    for day in range(NDAYS):\n",
    "\n",
    "        # loop for each decision time during the day\n",
    "        for time in range(NTIMES):\n",
    "\n",
    "            # Get the current timeslot\n",
    "            ts = (day) * 5 + time\n",
    "            \n",
    "            # State of the user at time ts\n",
    "            availability, fs, gs = determine_user_state(data[user][ts])\n",
    "\n",
    "            # Save user's availability\n",
    "            availability_matrix[user, ts] = availability\n",
    "            \n",
    "            # If user is available\n",
    "            if availability == 1:\n",
    "\n",
    "                # Draw from the posterior\n",
    "                beta_draws = posterior_draws_beta(post_mu, post_sigma)\n",
    "\n",
    "                # Calculate probability of (fs x beta) > n\n",
    "                #prob_fsb = calculate_post_prob(fs, beta_draws)\n",
    "            \n",
    "                \n",
    "                # Sample action with probability prob_fsb from bernoulli distribution\n",
    "                #action = select_action(prob_fsb)\n",
    "\n",
    "                # Bayesian LR to estimate reward\n",
    "                reward = calculate_reward(post_mu, post_sigma, fs, gs, sigma, action, prob_fsb)\n",
    "\n",
    "                # Save probability, features, action and reward\n",
    "                fs_matrix[user, ts] = fs\n",
    "                gs_matrix[user, ts] = gs\n",
    "                prob_matrix[user, ts] = prob_fsb\n",
    "                action_matrix[user, ts] = action\n",
    "                reward_matrix[user, ts] = reward\n",
    "            \n",
    "            # print(user, day, time, action_matrix[user, ts])\n",
    "\n",
    "        # Update posterior\n",
    "        post_mu, post_sigma = calculate_posterior(prior_sigma, prior_mu, sigma, availability_matrix[user][:ts + 1], prob_matrix[user][:ts + 1], \n",
    "                                                    reward_matrix[user][:ts + 1], action_matrix[user][:ts + 1], fs_matrix[user][:ts + 1], gs_matrix[user][:ts + 1])\n",
    "        print(post_mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap\n",
    "\n",
    "## A: Learning well on Average over time\n",
    "\n",
    "Below, using calculate_reward (using the true rewards seen in the data leads to odd performance), while our sanity check calculate_reward_old (using reward generated from a linear contextual bandit with gaussian noise) leads to somewhat more reasonable plots. However, it is still a bit odd performance since posteriors are 0 in (both?) cases.\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_sigma, prior_mu, sigma = load_priors()\n",
    "print(prior_mu)\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since 0 posterior tx betas are learned, test for different rewards.\n",
    "import random\n",
    "\n",
    "random.seed(123)\n",
    "true_mu= np.random.uniform(-1,1,(18,))\n",
    "true_sigma= np.random.uniform(0,.1,(18,18))\n",
    "true_sigma=np.matmul(np.transpose(true_sigma), true_sigma)\n",
    "\n",
    "#print(true_sigma)\n",
    "#print(true_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_user_state(data):\n",
    "    '''Determine the state of each user at each time point'''\n",
    "    availability = data[2]\n",
    "\n",
    "    features = OrderedDict()\n",
    "    features[\"intercept\"] = 1\n",
    "    features[\"dosage\"] = data[6]\n",
    "    features[\"engagement\"] = data[7]\n",
    "    features[\"other_location\"] = data[8]\n",
    "    # features[\"work_location\"] = data[9]\n",
    "    features[\"variation\"] = data[10]\n",
    "    features[\"temperature\"] = data[11]\n",
    "    features[\"logpresteps\"] = data[12]\n",
    "    features[\"sqrt_totalsteps\"] = data[13]\n",
    "    # features[\"prior_anti\"] = data[14]\n",
    "\n",
    "    prob=data[3]\n",
    "    action=data[4]\n",
    "    \n",
    "    reward = data[5]\n",
    "    \n",
    "    fs = np.array([v for k,v in features.items() if k in F_KEYS])\n",
    "    gs = np.array([v for k,v in features.items() if k in G_KEYS])\n",
    "\n",
    "    return availability, fs, gs, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate reward if not bootstrap through the linear model below\n",
    "# o.w. \n",
    "def calculate_reward(post_mu, post_sigma, fs, gs, sigma, action, prob, reward, IS_BOOTSTRAP, bootstrap_metadata_user={}):\n",
    "    if IS_BOOTSTRAP:\n",
    "        alpha0 =  bootstrap_metadata_user['baseline_theta'][:len(G_KEYS)].flatten()\n",
    "        alpha1 =  bootstrap_metadata_user['baseline_theta'][-len(F_KEYS):].flatten()\n",
    "        beta=bootstrap_metadata_user['baseline_theta'][-len(F_KEYS):].flatten()   \n",
    "        \n",
    "        estimated_reward = gs @ alpha0 + (prob * (fs @ alpha1)) + (action - prob) * (fs @ beta)\n",
    "\n",
    "        if bootstrap_metadata_user['useUser']: #user specific bootstrap\n",
    "            reward = bootstrap_metadata_user['resampled_residuals_i'][0,bootstrap_metadata_user['ts']] + estimated_reward\n",
    "        \n",
    "        else: # population bootstrap\n",
    "            reward= bootstrap_metadata_user['residuals'][bootstrap_metadata_user['ts']] + estimated_reward\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for testing - CAN REMOVE\n",
    "def calculate_reward_old(post_mu, post_sigma, fs, gs, sigma, action, prob, reward, IS_BOOTSTRAP, bootstrap_metadata_user={}):\n",
    "    if IS_BOOTSTRAP:\n",
    "        alpha0 =  bootstrap_metadata_user['baseline_theta'][:len(G_KEYS)].flatten()\n",
    "        alpha1 =  bootstrap_metadata_user['baseline_theta'][-len(F_KEYS):].flatten()\n",
    "        beta=bootstrap_metadata_user['baseline_theta'][-len(F_KEYS):].flatten()   \n",
    "        \n",
    "        estimated_reward = gs @ alpha0 + (prob * (fs @ alpha1)) + (action - prob) * (fs @ beta)\n",
    "\n",
    "        if bootstrap_metadata_user['useUser']: #user specific bootstrap\n",
    "            reward = bootstrap_metadata_user['resampled_residuals_i'][0,bootstrap_metadata_user['ts']] + estimated_reward\n",
    "        else: # population bootstrap\n",
    "            reward= bootstrap_metadata_user['residuals'][bootstrap_metadata_user['ts']] + estimated_reward\n",
    "    else:\n",
    "        # Get priors for alpha and beta\n",
    "        alpha_pmean, alpha_psd, beta_pmean, beta_psd = get_priors_alpha_beta(post_mu, post_sigma)\n",
    "\n",
    "        # Sample alpha, beta and noise\n",
    "        alpha0, alpha1, beta, et = sample_lr_params(alpha_pmean, alpha_psd, beta_pmean, beta_psd, sigma)\n",
    "\n",
    "        # Calculate reward\n",
    "        reward = gs @ alpha0 + (prob * (fs @ alpha1)) + (action - prob) * (fs @ beta) + et\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes: \n",
    "# - functionize to return relevant data from a run, \n",
    "# - run individually on each user, \n",
    "# - as of now: the only change with bootstrap run vs regular run is (i) reward assignment and (ii) data used\n",
    "#    - hence, we change the reward mechanism function accordingly\n",
    "# - minor bug in not learning individually for each user, and updating posterior appropriately\n",
    "# - dosage needs to be properly calculated\n",
    "\n",
    "def run_algorithm(data, user_indices, IS_BOOTSTRAP, posterior_results={}):    \n",
    "    # Load priors\n",
    "    prior_sigma, prior_mu, sigma = load_priors()\n",
    "\n",
    "    # DS to store availability, probabilities, features, actions and rewards\n",
    "    availability_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "    prob_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "    reward_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "    action_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "    fs_matrix = np.zeros((NUSERS, NDAYS * NTIMES, len(F_KEYS)))\n",
    "    gs_matrix = np.zeros((NUSERS, NDAYS * NTIMES, len(G_KEYS)))\n",
    "    \n",
    "    posteriors=[]\n",
    "\n",
    "    for i in range(len(user_indices)):\n",
    "        user=user_indices[i]\n",
    "        # Posterior initialized using priors\n",
    "        posteriors_i=[]\n",
    "        post_sigma, post_mu = np.copy(prior_sigma), np.copy(prior_mu)\n",
    "        bootstrap_metadata_user={'useUser': posterior_results['useUser'],'resampled_residuals_i': posterior_results['resampled_residuals_i'],'residuals': posterior_results['residuals'][user], 'baseline_theta': posterior_results['baseline_thetas'][user]} if IS_BOOTSTRAP else {}\n",
    "        for day in range(NDAYS):\n",
    "            for time in range(NTIMES):\n",
    "                # Get the current timeslot\n",
    "                ts = (day) * 5 + time\n",
    "\n",
    "                # State of the user at time ts\n",
    "                availability, fs, gs, reward = determine_user_state(data[user][ts])\n",
    "\n",
    "                # Save user's availability\n",
    "                availability_matrix[user, ts] = availability\n",
    "\n",
    "                # If user is available\n",
    "                if availability == 1:\n",
    "                    # Draw from the posterior\n",
    "                    beta_draws = posterior_draws_beta(post_mu, post_sigma)\n",
    "\n",
    "                    # Calculate probability of (fs x beta) > n\n",
    "                    prob_fsb = calculate_post_prob(fs, beta_draws)\n",
    "\n",
    "                    # Sample action with probability prob_fsb from bernoulli distribution\n",
    "                    action = select_action(prob_fsb)\n",
    "\n",
    "                    # Bayesian LR to estimate reward\n",
    "                    bootstrap_metadata_user['ts']= ts \n",
    "                    reward = calculate_reward(post_mu, post_sigma, fs, gs, sigma, action, prob_fsb, reward, IS_BOOTSTRAP, bootstrap_metadata_user)\n",
    "                    #reward = calculate_reward_old(post_mu, post_sigma, fs, gs, sigma, action, prob_fsb, reward, IS_BOOTSTRAP, bootstrap_metadata_user)\n",
    "                    #reward = calculate_reward_old(true_mu, true_sigma, fs, gs, sigma, action, prob_fsb, reward, IS_BOOTSTRAP, bootstrap_metadata_user)\n",
    "                    \n",
    "                    # Save probability, features, action and reward\n",
    "                    fs_matrix[i, ts] = fs\n",
    "                    gs_matrix[i, ts] = gs\n",
    "                    prob_matrix[i, ts] = prob_fsb\n",
    "                    action_matrix[i, ts] = action\n",
    "                    reward_matrix[i, ts] = reward\n",
    "\n",
    "            # Update posterior\n",
    "            post_mu, post_sigma = calculate_posterior(prior_sigma, prior_mu, sigma, availability_matrix[i][:ts + 1], prob_matrix[i][:ts + 1], \n",
    "                                                        reward_matrix[i][:ts + 1], action_matrix[i][:ts + 1], fs_matrix[i][:ts + 1], gs_matrix[i][:ts + 1])\n",
    "            posterior_it={'mu': post_mu, 'sigma': post_sigma}\n",
    "            posteriors_i.append(posterior_it)\n",
    "            #save post_mu, post_sigma for each person.\n",
    "            \n",
    "        posteriors.append(posteriors_i)\n",
    "\n",
    "    result={'posteriors': posteriors, 'rewards': reward_matrix, 'fs_matrix':fs_matrix, 'gs_matrix': gs_matrix, 'action_matrix':action_matrix, 'prob_matrix': prob_matrix, 'availability_matrix':availability_matrix}\n",
    "    result['useUser']=False\n",
    "    result['resampled_residuals_i']={}\n",
    "    result['resampled_residuals']={}\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for bootstrap run. in particular:\n",
    "# - add on \\hat{\\epsilon}_{it} to the result matrix, \n",
    "# - form baseline parameters with which to bootstrap (ie the prior). HERE is where we may specify alternative inputs of interest\n",
    "def add_residual_pairs(result, baseline=\"Prior\"):\n",
    "    prior_sigma, prior_mu, sigma = load_priors()\n",
    "    residual_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "    baseline_thetas={}\n",
    "    for user in range(NUSERS):\n",
    "        posterior_user_T=result['posteriors'][user][NDAYS-1]\n",
    "        for day in range(NDAYS):\n",
    "            for time in range(NTIMES):\n",
    "                ts = (day) * 5 + time\n",
    "                # get estiamted reward,\n",
    "                alpha, alpha_sd, beta, beta_sd = get_priors_alpha_beta(posterior_user_T['mu'], np.zeros(posterior_user_T['sigma'].shape))\n",
    "                estimated_reward = result['gs_matrix'][user, ts] @ alpha + (result['prob_matrix'][user, ts] * (result['fs_matrix'][user, ts] @ beta)) + (result['action_matrix'][user, ts] - result['prob_matrix'][user, ts]) * (result['fs_matrix'][user, ts] @ beta)\n",
    "                residual_matrix[user, ts]=result['rewards'][user][ts]-estimated_reward\n",
    "        baseline_theta=posterior_user_T['mu']\n",
    "        \n",
    "        if baseline==\"Prior\":\n",
    "            baseline_theta[-len(F_KEYS):]=prior_mu[-len(F_KEYS):]\n",
    "        \n",
    "        elif baseline==\"Truth\":#for testing\n",
    "            baseline_theta[-len(F_KEYS):]=true_mu[-len(F_KEYS):] \n",
    "        \n",
    "        baseline_thetas[user]=baseline_theta\n",
    "\n",
    "    # \n",
    "    result['residuals']=residual_matrix\n",
    "    result['baseline_thetas']=baseline_thetas\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Runner ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_user_state(data):\n",
    "    '''Determine the state of each user at each time point'''\n",
    "    availability = data[2]\n",
    "\n",
    "    features = OrderedDict()\n",
    "    features[\"intercept\"] = 1\n",
    "    features[\"dosage\"] = data[6]\n",
    "    features[\"engagement\"] = data[7]\n",
    "    features[\"other_location\"] = data[8]\n",
    "    # features[\"work_location\"] = data[9]\n",
    "    features[\"variation\"] = data[10]\n",
    "    features[\"temperature\"] = data[11]\n",
    "    features[\"logpresteps\"] = data[12]\n",
    "    features[\"sqrt_totalsteps\"] = data[13]\n",
    "    # features[\"prior_anti\"] = data[14]\n",
    "\n",
    "    prob=data[3]\n",
    "    action=data[4]\n",
    "    reward = data[5]\n",
    "    \n",
    "    fs = np.array([v for k,v in features.items() if k in F_KEYS])\n",
    "    gs = np.array([v for k,v in features.items() if k in G_KEYS])\n",
    "\n",
    "    return availability, fs, gs, reward,prob, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "np.random.seed(0)\n",
    "\n",
    "def run_algorithm(data, user_indices, IS_BOOTSTRAP, posterior_results={}):    \n",
    "    # Load priors\n",
    "    prior_sigma, prior_mu, sigma = load_priors()\n",
    "\n",
    "    # DS to store availability, probabilities, features, actions and rewards\n",
    "    availability_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "    prob_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "    reward_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "    action_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "    fs_matrix = np.zeros((NUSERS, NDAYS * NTIMES, len(F_KEYS)))\n",
    "    gs_matrix = np.zeros((NUSERS, NDAYS * NTIMES, len(G_KEYS)))\n",
    "    \n",
    "    posteriors=[]\n",
    "\n",
    "    for i in range(len(user_indices)):\n",
    "        nanHit=False\n",
    "        user=user_indices[i]\n",
    "        # Posterior initialized using priors\n",
    "        posteriors_i=[]\n",
    "        post_sigma, post_mu = np.copy(prior_sigma), np.copy(prior_mu)\n",
    "        \n",
    "        #bootstrap_metadata_user={'useUser': posterior_results['useUser'],'resampled_residuals_i': posterior_results['resampled_residuals_i'],'residuals': posterior_results['residuals'][user], 'baseline_theta': posterior_results['baseline_thetas'][user]} if IS_BOOTSTRAP else {}\n",
    "        for day in range(NDAYS):\n",
    "            for time in range(NTIMES):\n",
    "                # Get the current timeslot\n",
    "                ts = (day) * 5 + time\n",
    "\n",
    "                # State of the user at time ts\n",
    "                availability, fs, gs, reward,p_data,a_data = determine_user_state(data[user][ts])\n",
    "\n",
    "                # Save user's availability\n",
    "                availability_matrix[user, ts] = availability\n",
    "\n",
    "                # If user is available\n",
    "                if availability == 1:\n",
    "                    # Draw from the posterior\n",
    "                    ## beta_draws = posterior_draws_beta(post_mu, post_sigma)\n",
    "\n",
    "                    # Calculate probability of (fs x beta) > n\n",
    "                    prob_fsb = calculate_post_prob(fs, beta_draws)\n",
    "\n",
    "                    # Sample action with probability prob_fsb from bernoulli distribution\n",
    "                    action = select_action(prob_fsb)\n",
    "\n",
    "                    # Bayesian LR to estimate reward\n",
    "                    #bootstrap_metadata_user['ts']= ts \n",
    "                    #reward = calculate_reward(post_mu, post_sigma, fs, gs, sigma, action, prob_fsb, reward, IS_BOOTSTRAP, bootstrap_metadata_user)\n",
    "                    #reward = calculate_reward_old(post_mu, post_sigma, fs, gs, sigma, action, prob_fsb, reward, IS_BOOTSTRAP, bootstrap_metadata_user)\n",
    "                    #reward = calculate_reward_old(true_mu, true_sigma, fs, gs, sigma, action, prob_fsb, reward, IS_BOOTSTRAP, bootstrap_metadata_user)\n",
    "                    \n",
    "                    # Save probability, features, action and reward\n",
    "                    prob_matrix[i, ts] = p_data#prob_fsb\n",
    "                    action_matrix[i, ts] = a_data#action\n",
    "                    reward_matrix[i, ts] = reward\n",
    "                \n",
    "                fs_matrix[i, ts] = fs\n",
    "                gs_matrix[i, ts] = gs\n",
    "\n",
    "            #print(\"FS \"+str(fs_matrix))\n",
    "            #print(\"GS \"+str(gs_matrix))\n",
    "            #print(\"Prob \"+str(prob_matrix))\n",
    "            #print(\"Action \"+str(action_matrix))\n",
    "            #print(\"Reward \"+str(reward_matrix))\n",
    "            \n",
    "            # Update posterior\n",
    "            post_mu, post_sigma = calculate_posterior(prior_sigma, prior_mu, sigma, availability_matrix[i][:ts + 1], prob_matrix[i][:ts + 1], \n",
    "                                                        reward_matrix[i][:ts + 1], action_matrix[i][:ts + 1], fs_matrix[i][:ts + 1], gs_matrix[i][:ts + 1])\n",
    "            \n",
    "            if np.sum(np.isnan(post_mu))>0 and not nanHit:\n",
    "                print(\"User: \"+str(i)+\". Time: \"+str(time)+\", ts: \"+str(ts)) \n",
    "                nanHit=True\n",
    "            posterior_it={'mu': post_mu, 'sigma': post_sigma}\n",
    "            posteriors_i.append(posterior_it)\n",
    "            #save post_mu, post_sigma for each person.\n",
    "            \n",
    "        posteriors.append(posteriors_i)\n",
    "        \n",
    "    result={'posteriors': posteriors, 'rewards': reward_matrix, 'fs_matrix':fs_matrix, 'gs_matrix': gs_matrix, 'action_matrix':action_matrix, 'prob_matrix': prob_matrix, 'availability_matrix':availability_matrix}\n",
    "    result['useUser']=False\n",
    "    result['resampled_residuals_i']={}\n",
    "    result['resampled_residuals']={}\n",
    "    return result\n",
    "\n",
    "def initial_run():\n",
    "    data = load_data()\n",
    "    result=run_algorithm(data, [10], IS_BOOTSTRAP=False) #range(NUSERS), IS_BOOTSTRAP=False)\n",
    "    #with open('/Users/raphaelkim/Dropbox (Harvard University)/HeartStepsV2V3/Raphael/original_result_91.pickle', 'wb') as handle:\n",
    "    #    pickle.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return result\n",
    "\n",
    "result=initial_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(result['rewards'][0])\n",
    "data[10,0:10,[2, 5]]\n",
    "user=10\n",
    "timeStart=0\n",
    "timeEnd=35\n",
    "cols=[2,3,4,14,6]\n",
    "\n",
    "cols=[2,5]\n",
    "print(pd.DataFrame(data[user, 0:50])[cols])\n",
    "\n",
    "#print(sum(np.isnan(pd.DataFrame(data[user, 0:1350][5]))))\n",
    "\n",
    "#pd.DataFrame(data[0:91, 0:1350][5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[user][0:1350])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "result=run_algorithm(data, range(NUSERS), IS_BOOTSTRAP=False)\n",
    "\n",
    "baseline=\"Prior\" #\"Posterior\",\"Truth\"\n",
    "result=add_residual_pairs(result, baseline=baseline)\n",
    "result['useUser']=False\n",
    "\n",
    "B=2 # Number of bootstrap simulations\n",
    "bootstrapped_results={}\n",
    "for b in range(B):\n",
    "    resampled_indices = np.random.choice(range(NUSERS), NUSERS)\n",
    "    result_b=run_algorithm(data, resampled_indices, True, result)\n",
    "    bootstrapped_results[b]=result_b\n",
    "\n",
    "bs_avg_a = bootstrapped_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is there nan and 0000 posterior T effect when recalculating posterior from the og algorithm (Prasidh's data)??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(data[0, 380:420])[[3, 4, 14, 6]]\n",
    "for i in range(NUSERS):\n",
    "    #print(pd.DataFrame(data[i, :]).columns.values)\n",
    "    index_i=pd.DataFrame(data[i, :])[[2]].ne(0).idxmax()\n",
    "    \n",
    "    print(index_i)\n",
    "    \n",
    "    prob=pd.DataFrame(data[0, index_i:(index_i+1)])[[2,3,4,14,6]]\n",
    "    print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(data[0, 285:290])[[2,3,4,14,6]])\n",
    "\n",
    "print(pd.DataFrame(data[1, 0:35])[[2,3,4,14,6]])\n",
    "\n",
    "print(pd.DataFrame(data[2, 210:220])[[2,3,4,14,6]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(data[82, 0:35])[[2,3,4,14,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaner Analysis for Learning on Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import rpy2.robjects as robjects\n",
    "from collections import OrderedDict\n",
    "import scipy.stats as stats\n",
    "import scipy.linalg as linalg\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# %%\n",
    "PKL_DATA_PATH = \"/Users/raphaelkim/Dropbox (Harvard University)/HeartStepsV2V3/Raphael/all91.pkl\"\n",
    "PRIOR_DATA_PATH = \"/Users/raphaelkim/Dropbox (Harvard University)/HeartStepsV2V3/Raphael/bandit-prior.RData\"\n",
    "NDAYS = 90\n",
    "NUSERS = 91\n",
    "NTIMES = 5\n",
    "\n",
    "LAMBDA = 0.95\n",
    "\n",
    "F_KEYS = [\"intercept\", \"dosage\", \"engagement\", \"other_location\", \"variation\"]\n",
    "F_LEN = len(F_KEYS)\n",
    "G_KEYS = [\"intercept\", \"dosage\", \"engagement\", \"other_location\", \"variation\", \"temperature\", \"logpresteps\", \"sqrt_totalsteps\"]\n",
    "G_LEN = len(G_KEYS)\n",
    "\n",
    "#\"outputDir/results_{user}_{boot_num}.pkl\"\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = {\"availability\": availability_matrix, \"prob\": prob_matrix, \"action\": action_matrix, \"reward\": reward_matrix,\n",
    "#              \"fs\": fs_matrix, \"gs\": gs_matrix, \"post_mu\": post_mu_matrix, \"post_sigma\": post_sigma_matrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B: User Specific Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we do a user specific bootstrap: Each bootstrap trajectory is generated similarly as in the population bootstrap \n",
    "# with the only difference that the residual added to the reward at an available time point\n",
    "# is sampled with replacement from all of the residuals from this same user.\n",
    "def resample_user_residuals(result, i, baseline=\"Prior\"):\n",
    "    T= NDAYS * NTIMES\n",
    "    residual_matrix_resampled = np.zeros((1, T))\n",
    "    resampled_indices = np.random.choice(range(T), T)\n",
    "    residual_matrix_resampled[0,:]=result['residuals'][i][resampled_indices]\n",
    "    result['resampled_residuals_i']=residual_matrix_resampled\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=10 # Number of bootstrap simulations\n",
    "bootstrapped_results={}\n",
    "result['useUser']=True\n",
    "i=15\n",
    "\n",
    "for b in range(B):\n",
    "    result=resample_user_residuals(result, i) #using this\n",
    "    result_b=run_algorithm(data, [i], True, result)\n",
    "    bootstrapped_results[b]=result_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plotResult(bootstrapped_results, result, state, key=\"posteriors\", baseline=\"Posterior\", user=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary code for calculating interestingness according to the definition in JMIR draft\n",
    "I was initially thinking that we just calculate the difference of avergae (conditional) treatment effects in engaged vs not state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateInterestingness(result, x=0, y=35, delta1=0.463, delta2=1, key=\"posteriors\"):\n",
    "    standardizedEffects={}\n",
    "    engaged={}\n",
    "    for user in range(len(result[key])):#this will always be 1 for a user specific bootstrap\n",
    "        standardizedEffectsUser=[]\n",
    "        engagedUser=[]\n",
    "        for day in range(NDAYS):\n",
    "            for time in range(NTIMES):\n",
    "                ts = (day) * 5 + (NTIMES-1)\n",
    "\n",
    "                beta=result['posteriors'][user][day]['mu'][-len(F_KEYS):]\n",
    "                mean =result['fs_matrix'][user, ts] @ beta\n",
    "\n",
    "                sigma=result['posteriors'][user][day]['sigma'][-len(F_KEYS):, -len(F_KEYS):]\n",
    "                std=(result['fs_matrix'][user, ts] @ sigma) @ result['fs_matrix'][user, ts]\n",
    "                \n",
    "                standardizedEffectsUser.append(mean/std)\n",
    "                engagedUser.append(result['fs_matrix'][user, ts][2]) #check engagement is at index 2!!!\n",
    "        standardizedEffects[user]=np.array(standardizedEffectsUser)\n",
    "        engaged[user]=np.array(engagedUser)\n",
    "    result['standardizedEffects']=standardizedEffects\n",
    "    result['engaged']=engaged\n",
    "\n",
    "    # iterate through sliding windows\n",
    "    n=(y-1)//2\n",
    "    iterations=range(len(result[key]))\n",
    "    total=len(iterations)\n",
    "    statistics={}\n",
    "    for user in iterations:\n",
    "        statistic={}\n",
    "        tIndex=0\n",
    "        nUndeterminedSlidingWindows=0\n",
    "        nInterestingDeterminedWindows=0\n",
    "        nSlidingWindows=0\n",
    "        nDeterminedWindows=0\n",
    "        determinedTimes=[]\n",
    "        unDeterminedTimes=[]\n",
    "        for day in range(NDAYS):\n",
    "            for time in range(NTIMES):\n",
    "                ts = (day) * 5 + (NTIMES-1)\n",
    "                if result['availability_matrix'][user, ts]: \n",
    "                    nSlidingWindows=nSlidingWindows+1\n",
    "                    \n",
    "                    effects=[]\n",
    "                    engages=[]\n",
    "\n",
    "                    if ts <= n: \n",
    "                        effects=result['standardizedEffects'][user][0:ts+n]\n",
    "                        engages=result['engaged'][user][1:ts+n]\n",
    "                    elif ts > n and ts <= NDAYS*NTIMES-1-n:\n",
    "                        effects=result['standardizedEffects'][user][(ts-n):(ts+n)]\n",
    "                        engages=result['engaged'][user][(ts-n):(ts+n)]\n",
    "                    else:\n",
    "                        effects=result['standardizedEffects'][user][(ts-n):(NDAYS*NTIMES-1)]\n",
    "                        engages=result['engaged'][user][(ts-n):(NDAYS*NTIMES-1)]\n",
    "                    isUnderdetermined = (sum(engages) >=x) and (len(engages)-sum(engages) >= x)\n",
    "                    if not isUnderdetermined:\n",
    "                        nDeterminedWindows=nDeterminedWindows+1\n",
    "                        determinedTimes.append(ts)\n",
    "\n",
    "                        # claculate effects\n",
    "                        engageIndices=np.where(engages==1)[0]\n",
    "                        nonEngageIndices=np.where(engages==0)[0]\n",
    "                        avgEngage=np.mean(effects[engageIndices])\n",
    "                        avgNonEngage=np.mean(effects[nonEngageIndices])\n",
    "                        if avgEngage > avgNonEngage:\n",
    "                            nInterestingDeterminedWindows=nInterestingDeterminedWindows+1\n",
    "                    else:\n",
    "                        nUndeterminedSlidingWindows=nUndeterminedSlidingWindows+1\n",
    "                        unDeterminedTimes.append(ts)\n",
    "        if nSlidingWindows >0 and nDeterminedWindows >0:\n",
    "            statistic[\"r1\"]=nUndeterminedSlidingWindows/nSlidingWindows\n",
    "            statistic[\"r2\"]=nInterestingDeterminedWindows/nDeterminedWindows\n",
    "            statistic[\"isInteresting\"]=(statistic[\"r1\"]<delta1) and (abs(statistic[\"r2\"]-.5)>delta2)\n",
    "        else: \n",
    "            statistic[\"r1\"]=statistic[\"r2\"]=statistic[\"isInteresting\"]=None\n",
    "        statistic[\"determinedTimes\"]=determinedTimes\n",
    "        statistic[\"unDeterminedTimes\"]=unDeterminedTimes\n",
    "\n",
    "        statistic[\"engaged\"]=result['engaged'][user]\n",
    "        statistic[\"standardizedEffects\"]=result['standardizedEffects'][user]\n",
    "        statistics[user]=statistic\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interestingnessOriginal=calculateInterestingness(result)\n",
    "bsAvgInteresting=[]\n",
    "bsUserInteresting=[]\n",
    "for b in range(len(bs_avg_a)):\n",
    "    bsAvgInteresting.append(calculateInterestingness(bs_avg_a[b]))\n",
    "\n",
    "for b in range(len(bootstrapped_results)):\n",
    "    bsUserInteresting.append(calculateInterestingness(bootstrapped_results[b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotEngagementResult(result, user):\n",
    "    determinedTimes=result[user]['determinedTimes']\n",
    "    unDeterminedTimes=result[user]['unDeterminedTimes']\n",
    "    \n",
    "    bsThickness=1.5\n",
    "    opacity=1\n",
    "    plt.clf()\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(20)\n",
    "    f.set_figheight(10)\n",
    "    plt.plot(determinedTimes, result[user]['standardizedEffects'][determinedTimes], color='b', linewidth=bsThickness, alpha=opacity)\n",
    "    plt.plot(unDeterminedTimes, result[user]['standardizedEffects'][unDeterminedTimes], color='r',label=\"Bootstrapped Posterior Means\", linewidth=bsThickness, alpha=opacity)\n",
    "\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title('Stdized Posterior Tx Effect for engaged and not')\n",
    "    plt.ylabel('Stdized Posterior Tx Effect')\n",
    "    plt.xlabel('Decision Time') \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotEngagementResult(interestingnessOriginal, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random checks.\n",
    "\n",
    "t=np.array([1,0,1])\n",
    "indices=np.where(t==1)[0]\n",
    "\n",
    "f=np.array([11,10,11])\n",
    "np.mean(f[indices])\n",
    "\n",
    "print(result.keys())\n",
    "\n",
    "last=bootstrapped_results[0]['posteriors'][0][0]['mu']\n",
    "lastOg=result['posteriors'][i][0]['mu']\n",
    "\n",
    "for t in range(90):\n",
    "    v1=(np.linalg.norm(result['posteriors'][i][0]['mu']-lastOg))\n",
    "    v2=(np.linalg.norm(bootstrapped_results[0]['posteriors'][0][t]['mu']-last))\n",
    "    #print(\"Og: \"+str(v1)+\"\\t\\t Bs: \"+str(v2))\n",
    "    last=bootstrapped_results[0]['posteriors'][0][t]['mu']\n",
    "    lastOg=result['posteriors'][i][t]['mu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring curve summaries\n",
    "\n",
    "- calculate probabiliteis of curves\n",
    "- calculate probabilities of engage effect > not engage effect (given available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interestingnessOriginal\n",
    "#result\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# aggregate results\n",
    "def getProbabilities(result, search=\"interesting\"):\n",
    "    probMetric={}\n",
    "    for user in range(NUSERS):\n",
    "        tIndex=0\n",
    "        probs=[]\n",
    "        for day in range(NDAYS):\n",
    "            for time in range(NTIMES):\n",
    "                ts = (day) * 5 + (NTIMES-1)\n",
    "                val=0\n",
    "                if search==\"interesting\":\n",
    "                    #alpha0 = result['posteriors'][user][day]['mu'][:len(G_KEYS)]\n",
    "                    #alpha1 = result['posteriors'][user][day]['mu'][-len(F_KEYS):]\n",
    "\n",
    "                    #alpha0 =  bootstrap_metadata_user['baseline_theta'][:len(G_KEYS)].flatten()\n",
    "                    #alpha1 =  bootstrap_metadata_user['baseline_theta'][-len(F_KEYS):].flatten()\n",
    "                    #beta=bootstrap_metadata_user['baseline_theta'][-len(F_KEYS):].flatten()   \n",
    "                    \n",
    "                    #alpha0 =  bootstrap_metadata_user['baseline_theta'][:len(G_KEYS)].flatten()\n",
    "                    #alpha1 =  bootstrap_metadata_user['baseline_theta'][-len(F_KEYS):].flatten()\n",
    "                    #beta=bootstrap_metadata_user['baseline_theta'][-len(F_KEYS):].flatten()   \n",
    "        \n",
    "                    #estimated_reward = gs @ alpha0 + (prob * (fs @ alpha1)) + (action - prob) * (fs @ beta)\n",
    "                    beta = result['posteriors'][user][day]['mu'][-len(F_KEYS):]\n",
    "                    beta_psd = result['posteriors'][user][day]['sigma'][-len(F_KEYS):, -len(F_KEYS):]\n",
    "\n",
    "                    curFS=result['fs_matrix'][user, ts]\n",
    "                    curFS=curFS.reshape(curFS.shape[0],1)\n",
    "                    curFS=np.transpose(curFS)                \n",
    "\n",
    "                    curFS[0,2]=1\n",
    "                    mean1=np.matmul(curFS, beta)\n",
    "                    var1=np.matmul(curFS, beta_psd)\n",
    "                    var1=np.matmul(var1, np.transpose(curFS))                    \n",
    "                    \n",
    "                    curFS[0,2]=0\n",
    "                    mean2=np.matmul(curFS, beta)\n",
    "                    var2=np.matmul(curFS, beta_psd)\n",
    "                    var2=np.matmul(var2, np.transpose(curFS))                    \n",
    "                    #dist2=multivariate_normal(mean2, var2)  \n",
    "                    \n",
    "                    dist1Minus2=multivariate_normal(mean1-mean2, var1+var2)\n",
    "                    probs.append(dist1Minus2.cdf(0))\n",
    "                    # get mvn\n",
    "                #get p(tau()-tau()>0)\n",
    "                # get P(beta > beta_b)\n",
    "        probMetric[user]=probs\n",
    "        result['probMetricInteresting']=probMetric\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_time(result):\n",
    "    # aggregrate over time\n",
    "    vals=[]\n",
    "    for day in range(NDAYS):\n",
    "        for time in range(NTIMES):\n",
    "            val_t=0\n",
    "            for i in range(NUSERS):\n",
    "                ts = (day) * 5 + (NTIMES-1)\n",
    "                val_t=val_t+result['probMetricInteresting'][i][ts]\n",
    "            val_t=val_t/NUSERS\n",
    "            vals.append(val_t)\n",
    "    result['observedAvgProbMetricInteresting']=vals\n",
    "    return result\n",
    "\n",
    "result=getProbabilities(result)\n",
    "result=aggregate_time(result)\n",
    "true_p=sum(result['observedAvgProbMetricInteresting'])/len(result['observedAvgProbMetricInteresting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allBootstrappedPs=[]\n",
    "for b in range(B):\n",
    "    bootstrapped_results[b]=getProbabilities(bootstrapped_results[b])\n",
    "    bootstrapped_results[b]=aggregate_time(bootstrapped_results[b])\n",
    "    res_p=bootstrapped_results[b]['observedAvgProbMetricInteresting']\n",
    "    p_b=sum(res_p)/len(res_p)\n",
    "    allBootstrappedPs.append(p_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import percentileofscore\n",
    "true_p=sum(result['observedAvgProbMetricInteresting'])/len(result['observedAvgProbMetricInteresting'])\n",
    "print(true_p)\n",
    "print(allBootstrappedPs)\n",
    "percentileofscore(allBootstrappedPs, true_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prob curves greater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['posteriors'][0][0]['mu'][-len(F_KEYS):].shape)\n",
    "print(type(result['posteriors'][0][0]['mu'][-len(F_KEYS):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['posteriors'][0][0]['sigma'][-len(F_KEYS):, -len(F_KEYS):])\n",
    "state=np.array([1, 3.86, 1, 1, 0]) # following the target state in JMIR Draft 04-01-21\n",
    "state=state.reshape(state.shape[0],1)\n",
    "print(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interestingnessOriginal\n",
    "#result\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "state=np.array([1, 3.86, 1, 1, 0]) # following the target state in JMIR Draft 04-01-21\n",
    "state=state.reshape(state.shape[0],1)\n",
    "state=np.transpose(state)\n",
    "\n",
    "def computeDistributions(result):\n",
    "    distributionsByDay=[]\n",
    "    beta=np.zeros(result['posteriors'][0][0]['mu'][-len(F_KEYS):].shape)\n",
    "    beta_psd=np.zeros(result['posteriors'][0][0]['sigma'][-len(F_KEYS):, -len(F_KEYS):].shape)\n",
    "    for day in range(NDAYS):\n",
    "        for user in range(NUSERS):\n",
    "            beta = beta+ result['posteriors'][user][day]['mu'][-len(F_KEYS):]\n",
    "            beta_psd = beta_psd + result['posteriors'][user][day]['sigma'][-len(F_KEYS):, -len(F_KEYS):]\n",
    "        beta=beta/NUSERS\n",
    "        beta_psd=beta_psd/(NUSERS**2)\n",
    "        distribution_day={'mu': beta, 'sigma': beta_psd}\n",
    "        distributionsByDay.append(distribution_day)\n",
    "    return distributionsByDay\n",
    "\n",
    "# aggregate results\n",
    "def getProbabilitiesCurves(result, bootstrapped_results):\n",
    "    probs=[]\n",
    "    observed_distros=computeDistributions(result)\n",
    "    for b in range(B):\n",
    "        bootstrapped_distros=computeDistributions(bootstrapped_results[b])\n",
    "        for day in range(NDAYS):\n",
    "            mean=observed_distros[day]['mu']-bootstrapped_distros[day]['mu']\n",
    "            var=observed_distros[day]['sigma']+bootstrapped_distros[day]['sigma']\n",
    "            mean=np.matmul(state, mean)\n",
    "            var=np.matmul(np.matmul(state, var), np.transpose(state))\n",
    "            distDifference=multivariate_normal(mean, var)\n",
    "            #distDifference=multivariate_normal(observed_distros[day]['mu']-bootstrapped_distros[day]['mu'], observed_distros[day]['sigma']+bootstrapped_distros[day]['sigma'])\n",
    "            probs.append(distDifference.cdf(0))\n",
    "    result['bootstrapped_comparison_blue_over_black']=probs #list that p(blue > black_b) for each b, across all time points\n",
    "    return result\n",
    "\n",
    "result=getProbabilitiesCurves(result, bootstrapped_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['bootstrapped_comparison_blue_over_black'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(result['posteriors'][0])) #[user][ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "u=[1,2,3,4]\n",
    "m=[0,-.75,2,-.5]\n",
    "l=[-4,-3,-2,-1]\n",
    "labels=[\"one\", \"two\", \"three\", \"four\"]\n",
    "z=1.96\n",
    "color='#2187bb'\n",
    "horizontal_line_width=0.25\n",
    "dat={'u': u, 'm':m,'l':l, 'labels': labels}\n",
    "\n",
    "df=pd.DataFrame(dat)\n",
    "df=df.sort_values(by=['m'])\n",
    "remap={}\n",
    "for i in range(df.shape[0]):\n",
    "    remap[df.index.values[i]]=i\n",
    "df=df.rename(index = remap)\n",
    "for i in range(df.shape[0]):\n",
    "    left = i - horizontal_line_width / 2\n",
    "    top = df['u'][i]\n",
    "    right = i + horizontal_line_width / 2\n",
    "    bottom = df['l'][i]\n",
    "    label=df['labels'][i]\n",
    "    mean=df['m'][i]\n",
    "    \n",
    "    plt.plot([top, bottom], [label,label], color=color)\n",
    "    plt.plot([top, top], [left, right], color=color)\n",
    "    plt.plot([bottom, bottom],[left, right], color=color)\n",
    "    plt.plot(mean,i, 'o', color='#f44336')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "13c8aa5ca84d84b1eff6a50796abe4d89d2f98a257803d4f138445c9af5306f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
