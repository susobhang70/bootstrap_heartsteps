{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rpy2.robjects as robjects\n",
    "from collections import OrderedDict\n",
    "import scipy.stats as stats\n",
    "import scipy.linalg as linalg\n",
    "import argparse\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "PKL_DATA_PATH = \"/Users/raphaelkim/Dropbox (Harvard University)/HeartStepsV2V3/Raphael/all91.pkl\"\n",
    "PRIOR_DATA_PATH = \"/Users/raphaelkim/Dropbox (Harvard University)/HeartStepsV2V3/Raphael/bandit-prior.RData\"\n",
    "NDAYS = 90\n",
    "NUSERS = 91\n",
    "NTIMES = 5\n",
    "\n",
    "LAMBDA = 0.95\n",
    "\n",
    "F_KEYS = [\"intercept\", \"dosage\", \"engagement\", \"other_location\", \"variation\"]\n",
    "F_LEN = len(F_KEYS)\n",
    "G_KEYS = [\"intercept\", \"dosage\", \"engagement\", \"other_location\", \"variation\", \"temperature\", \"logpresteps\", \"sqrt_totalsteps\"]\n",
    "G_LEN = len(G_KEYS)\n",
    "\n",
    "E0 = 0.2\n",
    "E1 = 0.1\n",
    "\n",
    "true_mu= np.random.uniform(-1,1,(18,))\n",
    "true_sigma= np.random.uniform(0,.1,(18,18))\n",
    "true_sigma=np.matmul(np.transpose(true_sigma), true_sigma)\n",
    "\n",
    "# %%\n",
    "# Load data\n",
    "def load_data():\n",
    "    with open(PKL_DATA_PATH, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "    return data\n",
    "\n",
    "# %%\n",
    "# Load initial run result\n",
    "def load_initial_run(residual_path, baseline_thetas_path, baseline):\n",
    "    with open(residual_path, \"rb\") as f:\n",
    "        residual_matrix = pkl.load(f)\n",
    "    with open(baseline_thetas_path, \"rb\") as f:\n",
    "        baseline_pickle = pkl.load(f)\n",
    "    if baseline == \"Prior\":\n",
    "        baseline_thetas = baseline_pickle[\"prior\"]\n",
    "    elif baseline == \"Posterior\":\n",
    "        baseline_thetas = baseline_pickle[\"posterior\"]\n",
    "    elif baseline == \"Zero\":\n",
    "        baseline_thetas = baseline_pickle[\"all0TxEffect\"]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid baseline\")\n",
    "\n",
    "    return residual_matrix, baseline_thetas\n",
    "\n",
    "# %%\n",
    "def determine_user_state(data, dosage):\n",
    "    '''Determine the state of each user at each time point'''\n",
    "    availability = data[2]\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    features[\"engagement\"] = data[7]\n",
    "    features[\"other_location\"] = data[8]\n",
    "    # features[\"work_location\"] = data[9]\n",
    "    features[\"variation\"] = data[10]\n",
    "    features[\"temperature\"] = data[11]\n",
    "    features[\"logpresteps\"] = data[12]\n",
    "    features[\"sqrt_totalsteps\"] = data[13]\n",
    "    features[\"prior_anti\"] = data[14]\n",
    "    features[\"dosage\"] = LAMBDA * dosage + features[\"prior_anti\"]\n",
    "\n",
    "    features[\"intercept\"] = 1\n",
    "\n",
    "    fs = np.array([features[k] for k in F_KEYS])\n",
    "    gs = np.array([features[k] for k in G_KEYS])\n",
    "\n",
    "    prob=data[3]\n",
    "    action=data[4]\n",
    "    reward = data[5]\n",
    "    \n",
    "    return availability, fs, gs, features[\"dosage\"], reward, action, prob\n",
    "\n",
    "# %%\n",
    "def load_priors():\n",
    "    '''Load priors from RData file'''\n",
    "    robjects.r['load'](PRIOR_DATA_PATH)\n",
    "    priors = robjects.r['bandit.prior']\n",
    "    alpha_pmean = np.array(priors.rx2(\"mu1\"))\n",
    "    alpha_psd = np.array(priors.rx2(\"Sigma1\"))\n",
    "    beta_pmean = np.array(priors.rx2(\"mu2\"))\n",
    "    beta_psd = np.array(priors.rx2(\"Sigma2\"))\n",
    "    sigma = float(priors.rx2(\"sigma\")[0])\n",
    "\n",
    "    prior_sigma = linalg.block_diag(alpha_psd, beta_psd, beta_psd)\n",
    "    prior_mu = np.concatenate([alpha_pmean, beta_pmean, beta_pmean])\n",
    "\n",
    "    return prior_sigma, prior_mu, sigma\n",
    "\n",
    "# %%\n",
    "def get_priors_alpha_beta(post_mu, post_sigma):\n",
    "    '''Get alpha and beta priors from mu and sigma'''\n",
    "    alpha_pmean = post_mu[:G_LEN].flatten()\n",
    "    alpha_psd = post_sigma[:G_LEN, :G_LEN]\n",
    "    beta_pmean = post_mu[-F_LEN:].flatten()\n",
    "    beta_psd = post_sigma[-F_LEN:, -F_LEN:]\n",
    "\n",
    "    return alpha_pmean, alpha_psd, beta_pmean, beta_psd\n",
    "\n",
    "# %%\n",
    "def sample_lr_params(alpha_pmean, alpha_psd, beta_pmean, beta_psd, sigma):\n",
    "    '''Sample alpha, beta and noise from priors for BLR'''\n",
    "\n",
    "    alpha0 = np.random.multivariate_normal(alpha_pmean, alpha_psd)\n",
    "    alpha1 = np.random.multivariate_normal(beta_pmean, beta_psd)\n",
    "    beta = np.random.multivariate_normal(beta_pmean, beta_psd)\n",
    "    et = np.random.normal(0, np.sqrt(sigma**2))\n",
    "\n",
    "    return alpha0, alpha1, beta, et\n",
    "\n",
    "# %%\n",
    "def clip(x, eta = .2):\n",
    "    '''Clipping function'''\n",
    "    return min(1 - E0, max(x, E1))\n",
    "\n",
    "# %%\n",
    "def calculate_post_prob(fs, post_mu, post_sigma, eta = 0):\n",
    "    '''Calculate the posterior probability of Pr(fs * b > eta)'''\n",
    "\n",
    "    # Get beta's posterior mean and covariance\n",
    "    _, _, beta_pmean, beta_psd = get_priors_alpha_beta(post_mu, post_sigma)\n",
    "\n",
    "    # Calculate the mean of the fs*beta distribution\n",
    "    fs_beta_mean = fs.T.dot(beta_pmean)\n",
    "\n",
    "    # Calculate the variance of the fs*beta distribution\n",
    "    fs_beta_cov = fs.T @ beta_psd @ fs\n",
    "\n",
    "    # Calculate the probability of Pr(fs * b > eta) using cdf\n",
    "    post_prob = 1 - stats.norm.cdf(eta, fs_beta_mean, np.sqrt(fs_beta_cov))\n",
    "\n",
    "    # Clip the probability\n",
    "    phi_prob = clip(post_prob)\n",
    "    \n",
    "    return phi_prob\n",
    "\n",
    "# %%\n",
    "def calculate_phi(prob_matrix, action_matrix, fs_matrix, gs_matrix):\n",
    "    '''Calculate phi for each user at each time point'''\n",
    "    Phi = np.expand_dims(np.hstack((gs_matrix, fs_matrix * prob_matrix.reshape(-1, 1), \\\n",
    "                (fs_matrix * (action_matrix - prob_matrix).reshape(-1, 1)))), axis=2)\n",
    "    return Phi\n",
    "\n",
    "# %%\n",
    "def calculate_post_sigma(prior_sigma, sigma, availability_matrix, Phi):\n",
    "    '''Calculate the posterior sigma'''\n",
    "\n",
    "    # Phi squared\n",
    "    Phi_square = np.multiply(Phi, Phi.transpose(0, 2, 1))\n",
    "\n",
    "    # Sum of availability times Phi squared\n",
    "    avail_phi_squared_sum = np.sum(np.multiply(availability_matrix.reshape(-1, 1, 1), Phi_square), axis=0) / (sigma**2)\n",
    "\n",
    "    # Posterior sigma\n",
    "    post_sigma = np.linalg.inv(np.linalg.inv(prior_sigma) + avail_phi_squared_sum)\n",
    "\n",
    "    return post_sigma\n",
    "\n",
    "# %%\n",
    "def calculate_post_mu(prior_sigma, prior_mu, sigma, availability_matrix, reward_matrix, Phi, post_sigma):\n",
    "    '''Calculate the posterior mu'''\n",
    "\n",
    "    # Product of prior sigma inverse and prior mu\n",
    "    sig_mu = (np.linalg.inv(prior_sigma) @ prior_mu.T).reshape(-1, 1)\n",
    "    \n",
    "    # Product of Phi and reward\n",
    "    Phi_reward = np.multiply(Phi, reward_matrix.reshape(-1, 1, 1))\n",
    "\n",
    "    # Sum of availability times Phi and reward\n",
    "    avail_phi_reward_sum = np.sum(np.multiply(availability_matrix.reshape(-1, 1, 1), Phi_reward), axis=0)\n",
    "\n",
    "    # Posterior mu\n",
    "    post_mu = (post_sigma @ (sig_mu + avail_phi_reward_sum)) / (sigma ** 2)\n",
    "\n",
    "    return post_mu\n",
    "\n",
    "# %%\n",
    "def calculate_posterior(prior_sigma, prior_mu, sigma, availability_matrix, prob_matrix, reward_matrix, action_matrix, fs_matrix, gs_matrix):\n",
    "    '''Calculate the posterior distribution'''\n",
    "    \n",
    "    # Calculate phi(s, a)\n",
    "    Phi = calculate_phi(prob_matrix, action_matrix, fs_matrix, gs_matrix)\n",
    "\n",
    "    # Calculate posterior sigma\n",
    "    post_sigma = calculate_post_sigma(prior_sigma, sigma, availability_matrix, Phi)\n",
    "\n",
    "    # Calculate posterior mu\n",
    "    post_mu = calculate_post_mu(prior_sigma, prior_mu, sigma, availability_matrix, reward_matrix, Phi, post_sigma)\n",
    "    \n",
    "    return post_mu, post_sigma\n",
    "\n",
    "# %%\n",
    "def select_action(p):\n",
    "    '''Select action from bernoulli distribution with probability p'''\n",
    "    return stats.bernoulli.rvs(p)\n",
    "\n",
    "# o.w. \n",
    "def calculate_reward(mu, sigma, fs, gs, prob,action):\n",
    "    alpha0 =  mu[:len(G_KEYS)].flatten()\n",
    "    alpha1 =  mu[-len(F_KEYS):].flatten()\n",
    "    beta=mu[-len(F_KEYS):].flatten()   \n",
    "    \n",
    "    reward =  gs @ alpha0 + (action) * (fs @ beta)+np.random.normal()\n",
    "    return reward\n",
    "\n",
    "# %%\n",
    "def run_algorithm(data, user):\n",
    "    '''Run the algorithm for each user and each bootstrap'''\n",
    "\n",
    "    rewards=data[:,5]\n",
    "    rewards=list(rewards[~np.isnan(rewards)])\n",
    "    imputeRewardValue=sum(rewards)/len(rewards)\n",
    "    \n",
    "    # Load priors\n",
    "    prior_sigma, prior_mu, sigma = load_priors()\n",
    "\n",
    "    # Initializing dosage to first dosage value (can be non-zero if user was already in the trial)\n",
    "    dosage = data[0][6]\n",
    "\n",
    "    # Posterior initialized using priors\n",
    "    post_sigma, post_mu = np.copy(prior_sigma), np.copy(prior_mu)\n",
    "    post_sigma, post_mu=true_sigma,true_mu\n",
    "    post_mu=np.reshape(post_mu, (post_mu.shape[0], 1))\n",
    "    \n",
    "    # DS to store availability, probabilities, features, actions, posteriors and rewards\n",
    "    availability_matrix = np.zeros((NDAYS * NTIMES))\n",
    "    prob_matrix = np.zeros((NDAYS * NTIMES))\n",
    "    reward_matrix = np.zeros((NDAYS * NTIMES))\n",
    "    action_matrix = np.zeros((NDAYS * NTIMES))\n",
    "    fs_matrix = np.zeros((NDAYS * NTIMES, F_LEN))\n",
    "    gs_matrix = np.zeros((NDAYS * NTIMES, G_LEN))\n",
    "    post_mu_matrix = np.zeros((NDAYS * NTIMES, G_LEN + 2 * F_LEN))\n",
    "    post_sigma_matrix = np.zeros((NDAYS * NTIMES, G_LEN + 2 * F_LEN, G_LEN + 2 * F_LEN))\n",
    "    \n",
    "    for day in range(NDAYS):\n",
    "        # loop for each decision time during the day\n",
    "        for time in range(NTIMES):\n",
    "\n",
    "            # Get the current timeslot\n",
    "            ts = (day) * 5 + time\n",
    "            \n",
    "            # State of the user at time ts\n",
    "            availability, fs, gs, dosage, reward, action, prob_fsb = determine_user_state(data[ts], dosage)\n",
    "\n",
    "            if np.isnan(reward):\n",
    "                reward=imputeRewardValue\n",
    "\n",
    "            # Save user's availability\n",
    "            availability_matrix[ts] = availability\n",
    "            \n",
    "            # If user is available\n",
    "            if availability == 1:\n",
    "                # Calculate probability of (fs x beta) > n\n",
    "                #prob_fsb = calculate_post_prob(fs, post_mu, post_sigma)\n",
    "\n",
    "                # Sample action with probability prob_fsb from bernoulli distribution\n",
    "                #action = select_action(prob_fsb)\n",
    "                \n",
    "                # Save probability, features, action and reward\n",
    "                prob_matrix[ts] = prob_fsb\n",
    "                action_matrix[ts] = action\n",
    "                reward_matrix[ts] = calculate_reward(true_mu, true_sigma,fs, gs, prob_fsb, action)\n",
    "\n",
    "            # Save features and state\n",
    "            fs_matrix[ts] = fs\n",
    "            gs_matrix[ts] = gs\n",
    "                        \n",
    "            post_mu_matrix[ts] = post_mu[:,0]\n",
    "            post_sigma_matrix[ts] = post_sigma\n",
    "                            \n",
    "        # Update posterior\n",
    "        post_mu, post_sigma = calculate_posterior(prior_sigma, prior_mu, sigma, availability_matrix[:ts + 1], \n",
    "                                                    prob_matrix[:ts + 1], reward_matrix[:ts + 1], \n",
    "                                                    action_matrix[:ts + 1], fs_matrix[:ts + 1], gs_matrix[:ts + 1])\n",
    "\n",
    "    result = {\"availability\": availability_matrix, \"prob\": prob_matrix, \"action\": action_matrix, \"reward\": reward_matrix,\n",
    "            \"fs\": fs_matrix, \"gs\": gs_matrix, \"post_mu\": post_mu_matrix, \"post_sigma\": post_sigma_matrix}\n",
    "    return result\n",
    "                                                    \n",
    "\n",
    "def initial_run():\n",
    "    data = load_data()\n",
    "    allResults=[]\n",
    "    for i in range(NUSERS):\n",
    "        result_i=run_algorithm(data[i],i)\n",
    "        allResults.append(result_i)\n",
    "    return allResults,data\n",
    "\n",
    "def get_residual_pairs(results, baseline=\"Prior\"):\n",
    "    prior_sigma, prior_mu, sigma = load_priors()\n",
    "    residual_matrix = np.zeros((NUSERS, NDAYS * NTIMES))\n",
    "    baseline_thetas={}\n",
    "    for user in range(NUSERS):\n",
    "        posterior_user_T=results[user]['post_mu'][NDAYS-1]\n",
    "        for day in range(NDAYS):\n",
    "            for time in range(NTIMES):\n",
    "                ts = (day) * 5 + time\n",
    "                gs=results[user]['gs'][ts]\n",
    "                fs=results[user]['fs'][ts]\n",
    "                prob=results[user]['prob'][ts]\n",
    "                action=results[user]['action'][ts]\n",
    "                reward=results[user]['reward'][ts]\n",
    "\n",
    "                # get estimated reward,\n",
    "                alpha = posterior_user_T[:G_LEN].flatten()\n",
    "                alpha2=posterior_user_T[G_LEN:G_LEN+F_LEN].flatten()\n",
    "                beta = posterior_user_T[-F_LEN:].flatten()\n",
    "    \n",
    "                baseline_reward= gs[1] * alpha[1] #dosage*alpha_1\n",
    "                estimated_reward = baseline_reward + prob * (fs @ alpha2) + (action - prob) * (fs @ beta)\n",
    "                residual_matrix[user, ts]=reward-estimated_reward\n",
    "\n",
    "        baseline_theta=posterior_user_T\n",
    "        if baseline==\"Prior\":\n",
    "            baseline_theta[-len(F_KEYS):]=prior_mu[-len(F_KEYS):]\n",
    "        elif baseline==\"ZeroAtAll\": # need to add in additional for target states 0\n",
    "            baseline_theta[-len(F_KEYS):]=np.zeros(prior_mu[-len(F_KEYS):].shape)\n",
    "        baseline_thetas[user]=baseline_theta\n",
    "    \n",
    "    return residual_matrix, baseline_thetas\n",
    "\n",
    "np.random.seed(0)\n",
    "result,data=initial_run()\n",
    "res_matrix, baseline_prior = get_residual_pairs(result, \"Prior\")\n",
    "res_matrix, baseline_Posterior=get_residual_pairs(result, \"Posterior\")\n",
    "res_matrix, baseline_0Tx=get_residual_pairs(result, \"ZeroAtAll\")\n",
    "baselines={\"prior\": baseline_prior, \"posterior\": baseline_Posterior, \"all0TxEffect\": baseline_0Tx}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save additional pickled stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_mu)\n",
    "for i in range(NUSERS):\n",
    "    nanCount=0\n",
    "    nanCount=nanCount+np.count_nonzero(np.isnan(result[i]['gs']))\n",
    "    nanCount=nanCount+np.count_nonzero(np.isnan(result[i]['fs']))\n",
    "    nanCount=nanCount+np.count_nonzero(np.isnan(result[i]['availability']))\n",
    "    nanCount=nanCount+np.count_nonzero(np.isnan(result[i]['action']))\n",
    "    print(\"USER: \"+str(i)+\". nanCount: \"+str(nanCount))\n",
    "    print(\"posterior \"+str(result[i]['post_mu'][NTIMES*NDAYS-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/Users/raphaelkim/Dropbox (Harvard University)/HeartStepsV2V3/Raphael/baseline_parameters.pkl', 'wb') as handle:\n",
    "    pkl.dump(baselines, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('/Users/raphaelkim/Dropbox (Harvard University)/HeartStepsV2V3/Raphael/residual_matrix.pkl', 'wb') as handle:\n",
    "    pkl.dump(res_matrix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('/Users/raphaelkim/Dropbox (Harvard University)/HeartStepsV2V3/Raphael/original_result_91.pkl', 'wb') as handle:\n",
    "    pkl.dump(result, handle, protocol=pickle.HIGHEST_PROTOCOL) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(F_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getCoefficientData(result, index,z=1.96):\n",
    "    data_dict = {}\n",
    "    data_dict['User'] = [str(i) for i in range(NUSERS)]\n",
    "    data_dict['lower'] = []\n",
    "    data_dict['upper'] = []\n",
    "    data_dict['increment'] = []\n",
    "\n",
    "    data_dict['point_estimate']=[]\n",
    "    prior_sigma, prior_mu, sigma = load_priors()\n",
    "    beta_pmean = prior_mu[-F_LEN:].flatten()\n",
    "    beta_psd = prior_sigma[-F_LEN:, -F_LEN:]\n",
    "    std=math.sqrt(beta_psd[index,index])\n",
    "    increment=z*std\n",
    "\n",
    "    for i in range(NUSERS):\n",
    "        beta_pmean = result[i]['post_mu'][NTIMES*NDAYS-1][-F_LEN:].flatten()\n",
    "        beta_psd = result[i]['post_sigma'][NTIMES*NDAYS-1][-F_LEN:, -F_LEN:]\n",
    "        std=math.sqrt(beta_psd[index,index])\n",
    "        increment=z*std\n",
    "        upper=beta_pmean[index]+increment\n",
    "        lower=beta_pmean[index]-increment\n",
    "        data_dict['point_estimate'].append(beta_pmean[index])\n",
    "        data_dict['lower'].append(beta_psd[index])\n",
    "        data_dict['upper'].append(beta_psd[index])\n",
    "        data_dict['increment'].append(increment)\n",
    "    dataset = pd.DataFrame(data_dict)\n",
    "    data_dict['prior_point_estimate']=beta_pmean[index]\n",
    "    data_dict['prior_lower']=beta_psd[index]\n",
    "    data_dict['prior_upper']=beta_psd[index]\n",
    "    data_dict['prior_increment']=increment\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def plotCoefData(dat, color='#2187bb', horizontal_line_width=0.25):\n",
    "    NUSERS=len(dat['User'])\n",
    "    for i in range(NUSERS):\n",
    "        mean=dat['point_estimate'][i]\n",
    "        confidence_interval=dat['increment'][i]\n",
    "        left = i - horizontal_line_width / 2\n",
    "        top = mean - confidence_interval\n",
    "        right = i + horizontal_line_width / 2\n",
    "        bottom = mean + confidence_interval\n",
    "    \n",
    "        plt.plot([i, i], [top, bottom], color=color)\n",
    "        plt.plot([left, right], [top, top], color=color)\n",
    "        plt.plot([left, right], [bottom, bottom], color=color)\n",
    "        plt.plot(i, mean, 'o', color='#f44336')\n",
    "\n",
    "    plt.xticks(range(NUSERS), dat['User'])\n",
    "    plt.title('Confidence Intervals for Posterior at time T')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def coefficientEDA(result, index):\n",
    "    dat=getCoefficientData(result, index)\n",
    "    plotCoefData(dat)\n",
    "\n",
    "coefficientEDA(result, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "math.sqrt(5)\n",
    "print(F_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "13c8aa5ca84d84b1eff6a50796abe4d89d2f98a257803d4f138445c9af5306f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
